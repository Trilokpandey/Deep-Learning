{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small LSTM Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"Desktop\\\\wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  144411\n",
      "Total Vocab:  48\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  144311\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "144311/144311 [==============================] - 424s 3ms/step - loss: 2.9648\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.96485, saving model to weights-improvement-01-2.9648.hdf5\n",
      "Epoch 2/20\n",
      "144311/144311 [==============================] - 406s 3ms/step - loss: 2.7611\n",
      "\n",
      "Epoch 00002: loss improved from 2.96485 to 2.76114, saving model to weights-improvement-02-2.7611.hdf5\n",
      "Epoch 3/20\n",
      "144311/144311 [==============================] - 419s 3ms/step - loss: 2.6589\n",
      "\n",
      "Epoch 00003: loss improved from 2.76114 to 2.65892, saving model to weights-improvement-03-2.6589.hdf5\n",
      "Epoch 4/20\n",
      "144311/144311 [==============================] - 415s 3ms/step - loss: 2.5805\n",
      "\n",
      "Epoch 00004: loss improved from 2.65892 to 2.58046, saving model to weights-improvement-04-2.5805.hdf5\n",
      "Epoch 5/20\n",
      "144311/144311 [==============================] - 402s 3ms/step - loss: 2.5185\n",
      "\n",
      "Epoch 00005: loss improved from 2.58046 to 2.51850, saving model to weights-improvement-05-2.5185.hdf5\n",
      "Epoch 6/20\n",
      "144311/144311 [==============================] - 417s 3ms/step - loss: 2.4622\n",
      "\n",
      "Epoch 00006: loss improved from 2.51850 to 2.46218, saving model to weights-improvement-06-2.4622.hdf5\n",
      "Epoch 7/20\n",
      "144311/144311 [==============================] - 409s 3ms/step - loss: 2.4108\n",
      "\n",
      "Epoch 00007: loss improved from 2.46218 to 2.41084, saving model to weights-improvement-07-2.4108.hdf5\n",
      "Epoch 8/20\n",
      "144311/144311 [==============================] - 404s 3ms/step - loss: 2.3610\n",
      "\n",
      "Epoch 00008: loss improved from 2.41084 to 2.36103, saving model to weights-improvement-08-2.3610.hdf5\n",
      "Epoch 9/20\n",
      "144311/144311 [==============================] - 405s 3ms/step - loss: 2.3153\n",
      "\n",
      "Epoch 00009: loss improved from 2.36103 to 2.31529, saving model to weights-improvement-09-2.3153.hdf5\n",
      "Epoch 10/20\n",
      "144311/144311 [==============================] - 412s 3ms/step - loss: 2.2711\n",
      "\n",
      "Epoch 00010: loss improved from 2.31529 to 2.27111, saving model to weights-improvement-10-2.2711.hdf5\n",
      "Epoch 11/20\n",
      "144311/144311 [==============================] - 410s 3ms/step - loss: 2.2270\n",
      "\n",
      "Epoch 00011: loss improved from 2.27111 to 2.22703, saving model to weights-improvement-11-2.2270.hdf5\n",
      "Epoch 12/20\n",
      "144311/144311 [==============================] - 411s 3ms/step - loss: 2.1858\n",
      "\n",
      "Epoch 00012: loss improved from 2.22703 to 2.18579, saving model to weights-improvement-12-2.1858.hdf5\n",
      "Epoch 13/20\n",
      "144311/144311 [==============================] - 408s 3ms/step - loss: 2.1459\n",
      "\n",
      "Epoch 00013: loss improved from 2.18579 to 2.14588, saving model to weights-improvement-13-2.1459.hdf5\n",
      "Epoch 14/20\n",
      "144311/144311 [==============================] - 404s 3ms/step - loss: 2.1102\n",
      "\n",
      "Epoch 00014: loss improved from 2.14588 to 2.11022, saving model to weights-improvement-14-2.1102.hdf5\n",
      "Epoch 15/20\n",
      "144311/144311 [==============================] - 403s 3ms/step - loss: 2.0750\n",
      "\n",
      "Epoch 00015: loss improved from 2.11022 to 2.07502, saving model to weights-improvement-15-2.0750.hdf5\n",
      "Epoch 16/20\n",
      "144311/144311 [==============================] - 425s 3ms/step - loss: 2.0408\n",
      "\n",
      "Epoch 00016: loss improved from 2.07502 to 2.04084, saving model to weights-improvement-16-2.0408.hdf5\n",
      "Epoch 17/20\n",
      "144311/144311 [==============================] - 478s 3ms/step - loss: 2.0126\n",
      "\n",
      "Epoch 00017: loss improved from 2.04084 to 2.01259, saving model to weights-improvement-17-2.0126.hdf5\n",
      "Epoch 18/20\n",
      "144311/144311 [==============================] - 471s 3ms/step - loss: 1.9816\n",
      "\n",
      "Epoch 00018: loss improved from 2.01259 to 1.98159, saving model to weights-improvement-18-1.9816.hdf5\n",
      "Epoch 19/20\n",
      "144311/144311 [==============================] - 471s 3ms/step - loss: 1.9533\n",
      "\n",
      "Epoch 00019: loss improved from 1.98159 to 1.95332, saving model to weights-improvement-19-1.9533.hdf5\n",
      "Epoch 20/20\n",
      "144311/144311 [==============================] - 471s 3ms/step - loss: 1.9246\n",
      "\n",
      "Epoch 00020: loss improved from 1.95332 to 1.92459, saving model to weights-improvement-20-1.9246.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2c04ef908>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-19-1.9533.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" the hatter, 'you wouldn't talk\n",
      "about wasting it. it's him.'\n",
      "\n",
      "'i don't know what you mean,' said alic \"\n",
      "e, 'and io she dorstuse sait wothd to the thing theeg to toe theng the hareen  she housh natee thth the rabbit herdene thiee aadk to the white rabbit, and the white rabbit here the rimel of the soeee of the soeee, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel of the soeer, and the white rabbit here the rimel \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "import sys\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = numpy.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
